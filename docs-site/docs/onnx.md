---
id: onnx
title: ONNX
---

<!--- Licensed to the Apache Software Foundation (ASF) under one or more contributor license agreements.  See the NOTICE file distributed with this work for additional information regarding copyright ownership.  The ASF licenses this file to you under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License.  You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.  -->

[ONNX](https://onnx.ai/) is an open representation format for machine learning
models, which enables AI developers to use models across different libraries and
tools. SINGA supports loading ONNX format models for training and inference, and
saving models defined using SINGA APIs (e.g., [Module](./module)) into ONNX
format.

SINGA has been tested with the following
[version](https://github.com/onnx/onnx/blob/master/docs/Versioning.md) of ONNX.

| ONNX version | File format version | Opset version ai.onnx | Opset version ai.onnx.ml | Opset version ai.onnx.training |
| ------------ | ------------------- | --------------------- | ------------------------ | ------------------------------ |
| 1.6.0        | 6                   | 11                    | 2                        | -                              |

## General usage

### Loading an ONNX Model into SINGA

After loading an ONNX model from disk by `onnx.load`, you can prepare the SINGA
model by using `sonnx.prepare`. This function iterates and translates all the
nodes within the ONNX model's graph into SINGA operators, loads all stored
weights and infers each intermediate tensor's shape.

```python3
import onnx
from singa import device
from singa import sonnx

model_path = "PATH/To/ONNX/MODEL"
onnx_model = onnx.load(model_path)

# convert onnx graph nodes into SINGA operators
dev = device.create_cuda_gpu()
sg_ir = sonnx.prepare(onnx_model, device=dev, batchsize=1)
```

### Inference SINGA model

Once the model is created, you can do inference by calling `sg_ir.run`. The
input and output must be SINGA `Tensor` instances. Since SINGA model returns the
output as a list, if there is only one output, you just need to take the first
element from the output.

```python3
# can warp the following code in prepare()
# and provide a flag training=True/False?

class Infer:

    def __init__(self, sg_ir):
        self.sg_ir = sg_ir

    def forward(self, x):
        return sg_ir.run([x])[0]


data = get_dataset()
x = tensor.Tensor(device=dev, data=data)

model = Infer(sg_ir)
y = model.forward(x)
```

### Saving SINGA model into ONNX Format

Given the input tensors and the output tensors generated by the operators the
model, you can trace back all internal operations. Therefore, a SINGA model is
defined by the input and outputs tensors. To export a SINGA model into ONNX
format, you just need to provide the input and output tensor list.

```python3
# x is the input tensor, y is the output tensor
sonnx.to_onnx([x], [y])
```

### Re-training an ONNX model

To train (or refine) an ONNX model using SINGA, you need to set the internal
tensors to be trainable

```python3
class Infer:

    def __init__(self, sg_ir):
        self.sg_ir = sg_ir
        ## can wrap these codes in sonnx?
        for idx, tens in sg_ir.tensor_map.items():
            # allow the tensors to be updated
            tens.requires_grad = True
            tens.stores_grad = True

    def forward(self, x):
        return sg_ir.run([x])[0]

autograd.training = False
model = Infer(sg_ir)

autograd.training = True
# then you training the model like normal
# give more details??
```

### Transfer-learning an ONNX model

You also can append some layers to the end of ONNX model to do
transfer-learning. The `last_layers` means you cut the ONNX layers from [0,
last_layers]. Then you can append more layers by the normal SINGA model.

```python3
class Trans:

    def __init__(self, sg_ir, last_layers):
        self.sg_ir = sg_ir
        self.last_layers = last_layers
        self.append_linear1 = autograd.Linear(500, 128, bias=False)
        self.append_linear2 = autograd.Linear(128, 32, bias=False)
        self.append_linear3 = autograd.Linear(32, 10, bias=False)

    def forward(self, x):
        y = sg_ir.run([x], last_layers=self.last_layers)[0]
        y = self.append_linear1(y)
        y = autograd.relu(y)
        y = self.append_linear2(y)
        y = autograd.relu(y)
        y = self.append_linear3(y)
        y = autograd.relu(y)
        return y

autograd.training = False
model = Trans(sg_ir, -1)

# then you training the model like normal
```

## A Full Example

In this section, by using the
[mnist](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py)
model, an example of how to export, load, infer, re-train, and transfer learn a
model is demonstrated. You can try the code on
[colab](https://colab.research.google.com/drive/1-YOfQqqw3HNhS8WpB8xjDQYutRdUdmCq).

### Load and preprocess the dataset

Firstly, you need to import some necessary libraries and define some auxiliary
functions to download and preprocess the dataset. You can refer to the source
repo for the
[code](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L19-L84).

### MNIST model

You can define a class called
[**CNN**](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L86-L107)
to construct the MNIST model which consists of several convolutions, pooling,
fully connection and relu layers. A function called
[**accuracy**](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L110-L114)
is defined to calculate the accuracy of the model. A function called
[**train**](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L117-L148)
and a function called
[**test**](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L259-L274)
is defined to handle the training and prediction process.

### Train MNIST model and export it to ONNX

By using the functions defined above, you can train and export the model as
following:

```python
# create device
dev = device.create_cuda_gpu() # for gpu device
#dev = device.get_default_device() for cpu device

# create model
model = CNN()

# load data
train_x, train_y, valid_x, valid_y = load_dataset()

# normalization
train_x = train_x / 255
valid_x = valid_x / 255
train_y = to_categorical(train_y, 10)
valid_y = to_categorical(valid_y, 10)

# do training
autograd.training = True
x, y = train(model, train_x, train_y, dev=dev)
onnx_model = sonnx.to_onnx([x], [y])

# Save the ONNX model
model_path = os.path.join('/', 'tmp', 'mnist.onnx')
onnx.save(onnx_model, model_path)
print('The model is saved.')
```

### Inference

After export, you can find a file called **mnist.onnx** in the `'/tmp'`
directory. This model then can be imported by other platforms such as PyTorch.

Now, assuming you want to import this ONNX model into SINGA and do the inference
by using the validation dataset, you can define a class called
[**Infer**](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L155-L165).
The forward function of `Infer` will be called by the `test` function to do the
inference for validation dataset.

After calling **onnx.load** to load the ONNX model, the **soonx.prepare** can
initialize and return a SINGA model(**sg_ir** in the code). The sg_ir contains a
SINGA graph within it, and then you can run a step of inference by feeding input
to its run function.

```python
# load the ONNX model
onnx_model = onnx.load(model_path)
sg_ir = sonnx.prepare(onnx_model, device=dev) # parse and initiate to a SINGA model

# inference
print('The inference result is:')
test(Infer(sg_ir), valid_x, valid_y, dev=dev)
```

### Re-training

For re-training the model, you can define a function called
[**re_train**](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L168-L201).
The `autograd.training` should be set as **True** before re-training to enable
the gradient update.

```python
# load the ONNX model
onnx_model = onnx.load(model_path)
sg_ir = sonnx.prepare(onnx_model, device=dev)

# re-training
autograd.training = True
new_model = re_train(sg_ir, train_x, train_y, dev=dev)
test(new_model, valid_x, valid_y, dev=dev)
```

### Transfer learning

Transfer learning is available in SINGA. you can define a function called
[**Trans**](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L204-L221)
to append several layers after the imported ONNX model. For demonstration, the
code only appends several linear(fully connection) and relu after the ONNX
model. A function called
[**transfer_learning**](https://github.com/apache/singa/blob/master/examples/onnx/mnist.py#L224-L256)
is defined to handle the training process of the transfer-learning model.

```python
# load the ONNX model
onnx_model = onnx.load(model_path)
sg_ir = sonnx.prepare(onnx_model, device=dev)

# transfer-learning
autograd.training = True
new_model = transfer_learning(sg_ir, train_x, train_y, dev=dev)
test(new_model, valid_x, valid_y, dev=dev)
```

## ONNX Model Zoo

The [ONNX Model Zoo](https://github.com/onnx/models) is a collection of
pre-trained, state-of-the-art models in the ONNX format contributed by community
members. SINGA has supported several CV and NLP models now. More models are
going to be supported soon.

### Image Classification

These models take images as input(from the dataset of cifar10 or ImageNet), and
their purpose is to classify the image into some numbers of categories, such as
cat, dog, etc.

| Model Class                                                                                    | Reference                                          | Description                                                                                                                                                                                | Link                                                                                                                                                    |
| ---------------------------------------------------------------------------------------------- | -------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <b>[MobileNet](https://github.com/onnx/models/tree/master/vision/classification/mobilenet)</b> | [Sandler et al.](https://arxiv.org/abs/1801.04381) | MobileNets are based on a streamlined architecture that uses depth-wise separable convolutions to build light weight deep neural networks.                                                 | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1HsixqJMIpKyEPhkbB8jy7NwNEFEAUWAf) |
| <b>[ResNet18](https://github.com/onnx/models/tree/master/vision/classification/resnet)</b>     | [He et al.](https://arxiv.org/abs/1512.03385)      | A residual learning framework to ease the training of networks that are substantially deeper than those used previously.                                                                   | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1u1RYefSsVbiP4I-5wiBKHjsT9L0FxLm9) |
| <b>[VGG16](https://github.com/onnx/models/tree/master/vision/classification/vgg)</b>           | [Simonyan et al.](https://arxiv.org/abs/1409.1556) | A network increases its depth by using an architecture with very small (3x3) convolution filters, and it shows that a significant improvement by pushing the depth to 16-19 weight layers. | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/14kxgRKtbjPCKKsDJVNi3AvTev81Gp_Ds) |

### Object Detection

Object detection models detect the objects within an image and segment the
bounding box of each object.

| Model Class                                                                                                       | Reference                                             | Description                                                                                                                            | Link                                                                                                                                                    |
| ----------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <b>[Tiny YOLOv2](https://github.com/onnx/models/tree/master/vision/object_detection_segmentation/tiny_yolov2)</b> | [Redmon et al.](https://arxiv.org/pdf/1612.08242.pdf) | A real-time neural network for object detection that detects 20 different classes. It is a smaller version of the full YOLOv2 network. | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/11V4I6cRjIJNUv5ZGsEGwqHuoQEie6b1T) |

### Face Analysis

Face detection models extract features or recognize the emotions from human face
images.

| Model Class                                                                                               | Reference                                          | Description                                                                               | Link                                                                                                                                                    |
| --------------------------------------------------------------------------------------------------------- | -------------------------------------------------- | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <b>[ArcFace](https://github.com/onnx/models/tree/master/vision/body_analysis/arcface)</b>                 | [Deng et al.](https://arxiv.org/abs/1801.07698)    | A model uses the ResNet100 to obtain highly discriminative features for face recognition. | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1qanaqUKGIDtifdzEzJOHjEj4kYzA9uJC) |
| <b>[Emotion FerPlus](https://github.com/onnx/models/tree/master/vision/body_analysis/emotion_ferplus)</b> | [Barsoum et al.](https://arxiv.org/abs/1608.01041) | Deep CNN to deal with emotion recognition.                                                | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1XHtBQGRhe58PDi4LGYJzYueWBeWbO23r) |

### Machine Comprehension

The question answering model typically reads a context paragraph and then answer
several given questions.

| Model Class                                                                                           | Reference                                             | Description                                                                 | Link                                                                                                                                                    |
| ----------------------------------------------------------------------------------------------------- | ----------------------------------------------------- | --------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| <b>[BERT-Squad](https://github.com/onnx/models/tree/master/text/machine_comprehension/bert-squad)</b> | [Devlin et al.](https://arxiv.org/pdf/1810.04805.pdf) | A question answering model by using the BERT, a state of the art NLP model. | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1kud-lUPjS_u-TkDAzihBTw0Vqr0FjCE-) |

## Supported Operators

The following operators are supported:

- Conv
- Relu
- Constant
- MaxPool
- AveragePool
- Softmax
- Sigmoid
- Add
- MatMul
- BatchNormalization
- Concat
- Flatten
- Add
- Gemm
- Reshape
- Sum
- Cos
- Cosh
- Sin
- Sinh
- Tan
- Tanh
- Acos
- Acosh
- Asin
- Asinh
- Atan
- Atanh
- Selu
- Elu
- Equal
- Less
- Sign
- Div
- Sub
- Sqrt
- Log
- Greater
- HardSigmoid
- Identity
- Softplus
- Softsign
- Mean
- Pow
- Clip
- PRelu
- Mul
- Transpose
- Max
- Min
- Shape
- And
- Or
- Xor
- Not
- Neg
- Reciprocal
- LeakyRelu
- GlobalAveragePool
- ConstantOfShape
- Dropout
- ReduceSum
- ReduceMean
- LeakyRelu
- GlobalAveragePool
- Squeeze
- Unsqueeze
- Slice
- Ceil
- Split
- Gather
- Tile
- NonZero
- Cast
- OneHot

### Special comments for ONNX backend

- Conv, MaxPool and AveragePool

  Input must be 1d`(N*C*H)` or 2d`(N*C*H*W)` shape and `dilation` must be 1.

- BatchNormalization

  `epsilon` is 1e-05 and cannot be changed.

- Cast

  Only support cast between float32 and int32, other types will be casted to
  these two types.

- Squeeze and Unsqueeze

  If you encounter errors when you `Squeeze` or `Unsqueeze` between `Tensor` and
  `Scalar`, please report to us.

- Empty tensor

  Empty tensor is illegal in SINGA.

## Implementation

The code of SINGA ONNX locates at `python/singa/soonx.py`. There are three main
classes: `SingaFrontend`, `SingaBackend` and `SingaRep`. `SingaFrontend`
translates a SINGA model to the ONNX model; `SingaBackend` translates an ONNX
model to `SingaRep` object which stores all SINGA operators and tensors(the
tensor in this doc means SINGA `Tensor`); `SingaRep` then can be run like a
SINGA model.

### SingaFrontend

The entry function of `SingaFrontend` is `singa_to_onnx_model` which also is
called `to_onnx`. `singa_to_onnx_model` creates the ONNX model. In the ONNX
model, it also creates the ONNX graph by using `singa_to_onnx_graph`.

`singa_to_onnx_graph` accepts the output of the model, and recursively iterates
the SINGA model's graph from the output to get all operators to construct a
queue. The input and intermediate tensors, i.e, trainable weights, of the SINGA
model are collected at the same time. The input is stored in
`onnx_model.graph.input`; the output is stored in `onnx_model.graph.output`; the
trainable weights are stored in `onnx_model.graph.initializer`.

Then the SINGA operators in the queue are translated to ONNX operators one by
one. `_rename_operators` defines the operator's name mapping between SINGA and
ONNX. `_special_operators` defines the functions used to translate the operator.

In addition, some operators in SINGA has a different definition with ONNX, that
is, SINGA regards some inputs of some operators of ONNX as attributes, so
`_unhandled_operators` defines the functions used to handle the special
operator.

Since the bool type is regarded as int32 in SINGA, `_bool_operators` defines the
operators whose output is bool type.

### SingaBackend

The entry function of `SingaBackend` is `prepare` which checks the version of
the ONNX model and call `_onnx_model_to_singa_net` then.

The purpose of `_onnx_model_to_singa_net` is to get SINGA tensors and operators.
The tensors are stored in a dictionary by their name, and operators are stored
in a queue by the format of
`namedtuple('SingaOps', ['name', 'op', 'handle', 'forward'])`. For each
operator, `name` is its ONNX node name; `op` is the ONNX node; `forward` is the
SINGA operator's forward function; `handle` is prepared for some special
operators such as Conv and Pooling which have `handle` object.

The first step of `_onnx_model_to_singa_net` is to call `_init_graph_parameter`
to get all tensors within the model. For trainable weights, it can init SINGA
`Tensor` from `onnx_model.graph.initializer`. Please note, the weights may also
be stored within the graph's input or an ONNX node called `Constant`, SINGA can
also handle this situation.

Though all weights are stored within the ONNX model, the input of the model is
unknown but its shape and type. So SINGA supports two ways to init input, 1,
generate random tensor by its shape and type, 2, allow the user to assign the
input. The first way works fine for most models, however, for some models such
as BERT-Squad, the indices of the matrix cannot be randomly generated otherwise
it will incur errors.

Then, `_onnx_model_to_singa_net` iterators all nodes within the ONNX graph to
translate it to SIGNA operators. Also, `_rename_operators` defines the
operators' name mapping between SINGA and ONNX. `_special_operators` defines
which function to be used to translate the operator. `_run_node` runs the
generated SINGA model by its input tensors and store its output tensors for
being used by later operators.

The `prepare` finally returns a `SingaRep` object and stores all SINGA tensors
and operators within it.

### SingaRep

`SingaBackend` stores all SINGA tensors and operators. It provides a `run`
function to accept the input of the model and run the SINGA operators one by one
following the queue constructed above. The user can use `last_layers` to decide
to run the model until the last few layers. Set `all_outputs` as `False` to get
only the final output, `True` to also get all the intermediate output.
`batchsize` will update the batch size of model's input and output, the shape of
internal tensors will be inferred automatically.
